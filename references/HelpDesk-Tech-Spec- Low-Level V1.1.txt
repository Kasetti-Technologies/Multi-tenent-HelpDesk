- User: Technical Spec-Low-Level-V1.1 , Let us generate the full technical specification which should be very low level and should help in the complete generation of code without any ambiguity,  refereing to documents .[[mention:q0ghu4qt6ysse5ij19i3g213:Multi-Tenant-HelpDesk_Requirements_V1.1:NOTE]]  and [[mention:z9aui2tzrqwk0x58p7hqw4n9:Tech-Spec_low-level_V1.0:NOTE]] 

- Anara: Below is a unified, low-level technical specification (Technical Spec — Low-Level V1.1) written to be implementation-ready and unambiguous for engineers producing code, Helm/Terraform artifacts, and tests. It synthesizes the analyses in your folder and preserves provenance to the intermediate analyses. Where statements are sourced from the intermediate analyses, I include the original @ citations.

Executive summary
- Purpose: a multi-tenant, open-source-first AI Helpdesk platform combining Botpress-based chat flows, a RAG retrieval layer, multi-model LLM gateway, an agentic orchestrator for tool-calls, and integrated ticketing/handover, admin, and observability stacks. The design targets production-grade isolation, auditability, and pluggability for cloud and on-prem models @0 @29 @38.
- Primary implementation targets: Kubernetes (Helm), PostgreSQL (tenant registry + app metadata), Qdrant/Weaviate (vector store), Elasticsearch/OpenSearch (BM25), LangChain/LlamaIndex RAG service, Node.js LLM Gateway, FastAPI microservices for RAG and Tool Registry, Botpress (core), n8n + AutoGen/LangChain for agentic flows, and React/Next.js admin console. Observability via Prometheus/Grafana and tracing via OpenTelemetry/Jaeger @0 @2 @11 @29 @38 @41 @42 @43.

1) High-level architecture (components & responsibilities)
- Channels: Web widget (React/TS), Slack, MS Teams, WhatsApp, SMS, Email, Telephony connectors feed events into the chat engine @24 @38.
- Chat Engine: Botpress is the primary flow/runtime and UI Studio; Rasa can be introduced as a dedicated NLU microservice for mission-critical intent/entity extraction @29 @38 @42.
- Ingestion / ETL: Airflow or Prefect orchestrate connectors (Confluence, Google Drive, repos, PDFs, web) with parsers (PDFPlumber, Apache Tika) and Scrapy for crawls @21 @41 @40.
- Vector + Hybrid Retrieval: Qdrant or Weaviate for vector storage; Elasticsearch/OpenSearch for BM25 keyword ranking; a RAG server (FastAPI) implements rank-fusion and provenance @2 @11 @21 @32 @41.
- RAG Service: FastAPI microservice assembles context, returns answer + detailed sources (doc_id, section, score), and exposes /rag/query API contract @29 @41.
- LLM Gateway: Node.js service that routes requests to cloud or local LLMs, handles adaptive routing, circuit-breakers, retries, and Redis prompt caching @29 @31 @42.
- Agentic Orchestrator: AutoGen/LangChain/LangGraph + n8n-based workflows orchestrate multi-step tasks and tool-calls via a Tool Registry (FastAPI) @25 @29 @33 @43.
- Ticketing & Handover: WebSocket (Socket.IO /handover namespace) for live agent takeover; integrations to Chatwoot/Zendesk/Freshdesk/ServiceNow; ticketing CRUD in Postgres @29 @43.
- Admin & Analytics: React/Next.js admin console with prompt playground, ingestion controls, tenant registry UI, and n8n workflow editor; metrics surfaced from Prometheus/Grafana and conversation QA via OpenSearch/Kibana @29 @25 @33.

2) Non-functional priorities (explicit)
- Multi-tenant isolation, with options documented below; Row-Level Security (RLS) enforced on DB tables by default @40 @34.
- Auditability: immutable prompts, model calls, tool invocations, and admin actions logged for compliance @24 @34.
- Security: PII detection/redaction pre-storage, BYOK support via Vault, SSO/RBAC via Keycloak, tenant-scoped JWTs @24 @34 @13.
- Observability: metrics (deflection rate, fallback frequency, latency) in Prometheus; tracing via OpenTelemetry + Jaeger; replay and QA tooling via OpenSearch/Kibana @25 @34 @33.

3) Data models & low-level schema contracts
All schemas below are for direct copy/paste into DB migration files.

Tenant registry (Postgres) — canonical table
- SQL DDL (exact):
  CREATE TABLE tenants (
     tenant_id   UUID PRIMARY KEY,
     name        TEXT NOT NULL,
     domain      TEXT UNIQUE NOT NULL,
     config_json JSONB NOT NULL,       -- branding, connectors, SLAs
     created_at  TIMESTAMP DEFAULT now(),
     updated_at  TIMESTAMP DEFAULT now()
  ); @40

Ticket schema (Postgres) — canonical fields
- Example fields: ticket_id UUID PK, tenant_id UUID FK tenants(tenant_id), session_id UUID, status TEXT, priority TEXT, assigned_to TEXT, created_at, updated_at. Enforce tenant_id FK and RLS on this table @43 @34.

Embeddings / chunk metadata (Qdrant / Vector store)
- Per-tenant collections: each tenant gets a separate Qdrant collection/project. Store chunk_id, doc_id, tenant_id, text_excerpt, source_section, version_id, created_at, checksum @41 @40 @32.

Caching & ephemeral state
- Redis: prompt cache keyed by SHA256(tenant_id + prompt_template + context_hash) TTL 24h; Redis Streams as ingestion buffer for (tenant_id, chunk_id, text) tuples @31 @41 @42.

Audit log
- Immutable append-only audit table capturing: event_id, tenant_id, session_id, actor (model|agent|admin), event_type, payload (JSONB), timestamp. Ensure WAL-based retention & archival policies @34.

4) API contracts (OpenAPI-ready)
RAG service (FastAPI) — /rag/query POST
- Request (RagRequest): { tenant_id: string, question: string, top_k: integer }.
- Response (RagResponse): { answer: string, sources: [{ doc_id, section, score }] }.
- Implementation note: the RAG service must return provenance metadata for each source so the UI can show "Source: Doc X, Sect Y" and a confidence/trust score @41 @32 @21.

LLM Gateway (Node.js) — LLM call
- LlmRequest:
  {
    tenant_id: string,
    model: string,       // e.g., "gpt-4","mistral-7b"
    prompt: string,
    functions?: FunctionDef[]
  } @42 @31
- LlmResponse:
  {
    text: string,
    functionCall?: { name: string, arguments: any },
    tokens: { input: number, output: number }
  } @42 @31
- Caching: compute cache key via SHA256(tenant_id + prompt_template + context_hash) TTL 24h in Redis @42 @31.
- Circuit-breaker: failover rules — retries up to 2 times; if >5 failures/minute switch to local model and emit alert @42.

Tool Registry (FastAPI) — /tools/{tool_name}/invoke
- Request: { tenant_id, tool_args }.
- Response: standardized success payload and status; synchronous or asynchronous patterns supported.
- Definition: tools must provide OpenAPI/JSON-Schema definitions; orchestrator uses schema to build function-call payloads and validators @43 @35.

WebSocket Handover (Socket.IO) — namespace /handover
- Events:
  - bot_to_agent: { tenant_id, session_id, context }.
  - agent_to_user: { text, attachments }.
- Implementation: use Socket.IO namespaces and rooms per tenant+session; persist handover transcripts to audit log after session close @43.

Admin API (REST)
- Tenants CRUD, ingestion controls, model configuration, prompt templates, throttles, and billing/cost tags accessible via authenticated admin endpoints wired into Keycloak RBAC scopes @34 @25.

5) Ingestion & ETL (detailed, code-ready)
- Orchestration: Airflow DAGs (example snippet) scheduled per tenant or global with tenant-tagged tasks; tasks: fetch -> parse_and_chunk -> embed_and_upsert @40.
- Parsing:
  - PDF: PDFPlumber, chunk into ~500 token segments with metadata (doc_id, section, checksum) @40.
  - Confluence/Google Drive: REST connectors outputting markdown/plaintext with change detection via checksums @40.
  - Web: Scrapy crawlers obey robots.txt and scope configs @41.
- Buffering & workers:
  - Push raw chunks to Redis Streams (tenant-scoped stream names).
  - Worker reads stream, computes embeddings using Sentence-Transformers (all-mpnet-base-v2) locally or OpenAI embeddings as configured, then upserts into Qdrant with metadata @41.
- Incremental / change detection:
  - Track checksums; on mismatch emit Kafka event or Airflow trigger to re-chunk and upsert updated chunks; stale-embedding detection must be scheduled and reindexed automatically @21 @41.

6) Retrieval & ranking (hybrid + rank fusion)
- Retrieval steps (exact algorithm):
  1. Vector search: query Qdrant top_k vectors with tenant context.
  2. BM25: query Elasticsearch/OpenSearch top_k docs with tenant context.
  3. Rank-fusion: normalize both score sets and compute final score by normalized average (or a supervised reranker if enabled). Selected chunks include doc_id, section, score, and trust metadata @41 @35 @21.
- Context window management:
  - Dynamic pruning/expansion by model type and current dialog length; assemble contexts up to model limit applying semantic deduplication and chunk scoring heuristics @21 @35.
- Provenance & UI:
  - RAG must return doc_id/section/score for each chunk so admin/UI can display grounded citation and confidence; store source version id for auditability @21 @35 @29.

7) LLM strategy & orchestration (routing, fallback, cost controls)
- Model categories:
  - High-accuracy cloud (e.g., GPT-4) for compliance-critical queries.
  - Cost-efficient local models (Mistral 7B) for high-volume FAQs.
  - On-prem fallback (Llama 3-8B) for privacy-sensitive scenarios @16 @0 @11.
- Routing logic:
  - Use tenant.config_json to determine model preference (high_accuracy_model, cost_model, fallback_model).
  - Use latency/cost thresholds, confidence score heuristics, and token limits to route requests @29 @31.
  - If model confidence < threshold, escalate to fallback model; if still below threshold, escalate to human handover @16 @31.
- Function calling:
  - Implement function-call framework where LLM returns a structured functionCall (name + args) validated against Tool Registry schemas @21 @31 @35.
  - Orchestrator must verify post-call results before committing (post-call verification steps) @35.

8) Agentic orchestrator & tool-calls (definite details)
- Core runtime: AutoGen/LangChain (agents) + LangGraph for graph orchestration, workflows authored in n8n embedded in admin console for no-code orchestration @25 @33.
- Tool Registry: FastAPI service that exposes tools via OpenAPI/JSON-Schema definitions; endpoints of pattern /tools/{tool_name}/invoke accept standard payloads and return structured outputs for verification @43 @35.
- Example orchestrator flow:
  - AutoGen decomposes user goal, calls ToolInvoker nodes in n8n sequentially/parallel, validates outputs, writes tickets via tool create_ticket() and notifies user @42 @43.
- Governance: Control Tower enforces approval gates for high-risk tools, retry policies, and mandatory logging for all agentic actions @25 @35.

9) Multi-tenant architecture (isolation patterns & context propagation)
- Supported isolation patterns (choose per-tenant):
  1. Shared single-instance, shared schema with tenant_id tagging + RLS (cost-effective) @16 @30.
  2. Single-instance, separate schema per tenant (moderate isolation) @16 @30.
  3. Multi-instance per tenant (full isolation) via dedicated runtime/Helm/Terraform per tenant (for sensitive/high-compliance customers) @16.
  4. Hybrid: mix based on SLA/residency needs @15 @25.
- Tenant context propagation:
  - tenant_id must be included/validated in HTTP headers, JWT claims, or URL prefix and carried across API gateway -> LLM Gateway -> RAG -> Botpress -> Vector queries @15 @29.
- Vector store tenancy:
  - One collection per tenant in Qdrant or one project per tenant in Weaviate; queries must include tenant-scoped filters @5 @32.
- Configuration registry:
  - Central metadata service holding per-tenant config (branding, connectors, ingestion schedules, model throttles) referenced by LLM Gateway and ingestion pipelines @15 @25.

10) Security, compliance, governance (low-level)
- PII handling:
  - PII detection and redaction via tools like Microsoft Presidio executed before any storage in embeddings or chats; redaction must be configurable per-tenant @24 @34.
- Encryption & BYOK:
  - Integrate HashiCorp Vault for tenant-specific keys and support BYOK encryption for sensitive tenants @13 @34.
- Authentication & Authorization:
  - Keycloak for SSO and multi-tenant RBAC; tenant-scoped JWTs with tenant_id claim and scoped permissions @24 @34.
- Audit & immutability:
  - Promulgate immutable audit trails for prompts, model responses, function calls, tool invocations, and agent actions with tamper-evident storage and retention policies @24 @34.
- Policy enforcement:
  - Compliance Validator Agent (recommended) to review high-risk responses before delivery (optional advanced step) @37.

11) Observability, QA & continuous improvement
- Metrics:
  - Track deflection rate, fallback frequency, LLM latency, cost per tenant, SLA adherence, and average resolution time in Prometheus/Grafana @25 @34.
- Tracing & replay:
  - OpenTelemetry + Jaeger for traces; conversation replay and search via OpenSearch/Kibana for QA and root-cause analysis @25 @33.
- Experimentation:
  - Prompt A/B testing with live variant analytics and automated champion selection; store variant metadata and metrics for statistical comparison @24 @26.
- Active learning:
  - Surface low-confidence/high-volume queries in admin console; collect agent feedback to retrain rerankers and prompts @25.

12) Deployment, infra, and operational artifacts
- Containerization & packaging:
  - Dockerize every microservice; provide Helm charts for core stack: botpress, rag-service, llm-gateway, tool-registry, qdrant, elasticsearch/opensearch, postgres, redis, n8n, admin-app @10 @38 @40.
- IaC:
  - Provide Terraform modules for infra provisioning (k8s clusters, managed Postgres, object storage for backups, ingress, cert-manager), with per-tenant overlay patterns for hybrid isolation @19 @10.
- Secrets & config:
  - Store secrets in Vault; use Kubernetes External Secrets to inject into pods. Tenant config is stored in Postgres config_json with secrets stored in Vault referenced by key id @13 @34.
- CI/CD:
  - Use pipeline that runs unit tests, contract tests (OpenAPI) for RAG & Tool Registry, security scans, and integration tests including WebSocket handover tests and RAG provenance checks @19 @33.

13) Detailed implementation roadmap (phased, with deliverables)
Phase 0 — Preparation
- Fork and containerize Botpress; create base Helm charts; set up dev k8s environment; provision Postgres and Redis; create tenant registry schema @10 @40.

Phase 1 — MVP (thin surface, high value)
- Deploy Qdrant, LangChain RAG server, Node.js LLM gateway routing to one cloud model, Botpress web widget, Airflow basic ingestion for Confluence/PDFs, simple Chatwoot/Zendesk handover, admin console with tenant CRUD and a prompt playground; implement Redis caching and basic circuit-breaker @10 @30 @41 @42 @43.

Phase 2 — Harden & expand
- Add BM25 with Elasticsearch and rank-fusion; implement PII redaction pipeline; per-tenant collections and RLS; add agentic orchestrator and Tool Registry; implement observability dashboards and tracing @21 @35 @34 @33.

Phase 3 — Scale & advanced features
- Add multi-model routing across cloud/local, function-calling governance gates, prompt A/B automated championing, BYOK, model contextual protocol (MCP), and hybrid deployment patterns per tenant @16 @25 @37.

14) Test plans & acceptance criteria (must be automated)
- Unit tests for all microservices including deterministic LLM Gateway behavior using recorded model responses.
- Contract tests: OpenAPI-based request/response validation for /rag/query and /tools/* endpoints.
- End-to-end tests:
  - Ingestion pipeline: ingestion -> embeddings -> Qdrant upsert -> RAG retrieval returns expected sources for seeded docs.
  - Handover: WebSocket event flow through /handover and persisted audit trail.
  - Multi-tenant isolation: tests asserting data cannot cross tenant boundaries (Row-Level Security enforced).
- Load tests:
  - Simulate high QPS for vector search and LLM gateway; verify circuit-breaker behavior and fallback routing.
- Security tests:
  - PII injection attempts must be redacted before storage; secrets rotation tests for Vault keys.

15) Example low-level code snippets (ready to paste)
- Airflow DAG (ingest_cms_docs) — snippet for scheduled ingestion and chunk pipeline @40.
- RAG FastAPI endpoint skeleton — implement POST /rag/query returning answer + sources with doc_id, section, score @41.
- Tool Registry FastAPI snippet:
  @app.post("/tools/{tool_name}/invoke")
  def invoke_tool(tool_name: str, args: dict):
      tool = tool_definitions[tool_name]
      return tool.execute(args) @43
- LLM Gateway interfaces (TypeScript):
  interface LlmRequest { tenant_id: string; model: string; prompt: string; functions?: FunctionDef[] } interface LlmResponse { text: string; functionCall?: { name: string; arguments: any }; tokens: { input: number; output: number; } } @42

16) Open-source-only stack alternatives (explicit)
- ETL: Airflow + Scrapy + PDFPlumber/Tika @11 @40.
- Vector DB: Qdrant or Weaviate @11 @40.
- Embeddings: Sentence-Transformers (all-mpnet-base-v2) @41.
- RAG frameworks: LlamaIndex or LangChain @11.
- LLM hosting: OpenLLM or BentoML serving Mistral/Llama 3 locally @11 @8.
- Chat & Inbox: Botpress + Chatwoot; Rasa optional for NLU @8 @29.
- Observability: OpenTelemetry + Jaeger; Prometheus + Grafana @13 @33.

17) Risks, gaps & recommended next artifacts (low-level)
- Provenance UX: ensure UI displays exact doc section and trust/confidence scores with link-to-original and version id for audits @21 @35.
- Reranker training data: supervised reranker will require labeled relevance data from past tickets; include data export/export pipelines for offline training @11 @35.
- Governance for tool-calls: define approval gates and risk levels for tools; implement Control Tower before running high-risk tool-calls in production @35 @37.
- Helm/Chart completeness: provide example values for multi-tenant overlays (shared vs. dedicated) and per-tenant resource quotas @10 @19.

18) Appendices — references to the intermediate analyses (preserved citations)
This specification draws and consolidates the low-level designs and implementation guidance from the intermediate analyses in this folder: foundational architecture, component-level choices (Botpress core, RAG, LLM Gateway, vector store), multi-tenancy patterns, ingestion pipelines, agentic orchestration, and the concrete API/schema contracts @0 @2 @5 @7 @8 @10 @11 @12 @13 @15 @16 @17 @18 @19 @21 @22 @23 @24 @25 @26 @29 @30 @31 @32 @33 @34 @35 @36 @37 @38 @39 @40 @41 @42 @43.

Deliverables I can produce next (pick one)
- Full repository scaffold (monorepo) with service templates, Dockerfiles, example Helm charts, and skeletons for RAG FastAPI, Node LLM Gateway, Tool Registry, Botpress extension, and admin console.
- OpenAPI specs for RAG and Tool Registry and contract tests.
- Terraform + Helm example for both shared-schema and per-tenant dedicated deployments.
- End-to-end test harness (pytest + Playwright) for RAG provenance and WebSocket handover flows.

Which deliverable would you like me to generate first?

- User: All,Full repository scaffold (monorepo) with service templates, Dockerfiles, example Helm charts, and skeletons for RAG FastAPI, Node LLM Gateway, Tool Registry, Botpress extension, and admin console.
OpenAPI specs for RAG and Tool Registry and contract tests.
Terraform + Helm example for both shared-schema and per-tenant dedicated deployments.
End-to-end test harness (pytest + Playwright) for RAG provenance and WebSocket handover flows.

- Anara: Direct answer — I will generate a complete, implementation-ready monorepo scaffold plus all artifacts you requested: service templates, Dockerfiles, example Helm charts, OpenAPI specs for RAG and Tool Registry with contract tests, Terraform + Helm examples for both shared-schema and per-tenant dedicated deployments, and an end-to-end test harness (pytest + Playwright) for RAG provenance and WebSocket handover flows. This deliverable follows the low-level design and contracts in your folder and is designed so engineers can begin coding with minimal interpretation required @1 @11.

Below I present:
- 1) a canonical monorepo layout (file tree) you can create immediately;
- 2) per-service templates and responsibilities (RAG, LLM Gateway, Tool Registry, Botpress extension, Admin UI, workers);
- 3) concrete Dockerfile examples for each service (copy/paste-ready);
- 4) example Helm chart skeletons + values.yaml snippets for each service and notes for multi-tenant overlays (shared-schema vs per-tenant) @5 @12;
- 5) OpenAPI specs (YAML) for /rag/query and /tools/{tool_name}/invoke plus suggested pydantic models and contract-test approach (pytest + schemathesis or rptest style) @6 @7;
- 6) Terraform skeleton modules and usage examples for (A) shared-schema cluster and (B) per-tenant dedicated deployment overlay, plus notes for secrets (Vault) and GitOps/ArgoCD flows @5 @21;
- 7) End-to-end test harness: pytest unit/integration tests for ingestion → embedding → RAG provenance and Playwright + pytest for WebSocket handover flows with example tests and CI steps @2 @6 @7;
- 8) A checklist of next git commits/instructions to bootstrap the repo.

Where I reference requirements and implementation constraints I cite the source lines from your materials so you can trace every decision back to the original specs. Each factual statement that’s drawn from the documents is cited inline.

1) Monorepo file tree (canonical)
Create repository root named multi-tenant-helpdesk/ with this suggested tree (copy/paste into your shell as mkdir -p ... then git init). The tree is implementation-ready and maps to the components in the technical spec @1 @11.

multi-tenant-helpdesk/
├─ README.md
├─ LICENSE
├─ .gitignore
├─ infra/
│  ├─ helm-charts/
│  │  ├─ rag-service/
│  │  │  ├─ Chart.yaml
│  │  │  ├─ values.yaml
│  │  │  └─ templates/
│  │  │     ├─ deployment.yaml
│  │  │     └─ service.yaml
│  │  ├─ llm-gateway/
│  │  ├─ tool-registry/
│  │  ├─ botpress/
│  │  └─ admin-ui/
│  ├─ terraform/
│  │  ├─ modules/
│  │  │  ├─ k8s-cluster/
│  │  │  ├─ postgres/
│  │  │  └─ qdrant/
│  │  ├─ shared-deploy.tf
│  │  └─ per-tenant-deploy.tf
│  └─ argocd-apps/    # GitOps manifests for ArgoCD syncs
├─ services/
│  ├─ rag-service/            # FastAPI RAG microservice (Python)
│  │  ├─ app/
│  │  │  ├─ main.py
│  │  │  ├─ api/
│  │  │  │  └─ rag.py
│  │  │  ├─ models/
│  │  │  │  └─ schemas.py
│  │  │  ├─ retrieval/
│  │  │  │  ├─ qdrant_client.py
│  │  │  │  └─ bm25_client.py
│  │  │  └─ context_assembler.py
│  │  ├─ Dockerfile
│  │  └─ tests/
│  │     └─ test_rag_contract.py
│  ├─ llm-gateway/            # Node.js gateway
│  │  ├─ src/
│  │  │  ├─ index.ts
│  │  │  ├─ controllers/
│  │  │  │  └─ llmController.ts
│  │  │  └─ services/
│  │  │     └─ modelRouter.ts
│  │  ├─ Dockerfile
│  │  └─ tests/
│  ├─ tool-registry/          # FastAPI tool invocation service
│  │  ├─ app/
│  │  │  ├─ main.py
│  │  │  ├─ tools.py
│  │  │  └─ schemas.py
│  │  ├─ Dockerfile
│  │  └─ tests/
│  ├─ ingestion-worker/       # Python workers reading Redis Streams to embed and upsert to Qdrant
│  │  ├─ worker.py
│  │  ├─ Dockerfile
│  │  └─ tests/
│  ├─ botpress-extensions/    # custom actions or hooks for Botpress
│  │  └─ README.md
│  └─ admin-ui/               # Next.js admin console + embedded n8n editor
│     ├─ app/
│     ├─ Dockerfile
│     └─ tests/
├─ tests/
│  ├─ e2e/
│  │  ├─ playwright/          # Playwright configs & tests for WebSocket handover
│  │  └─ pytest/              # pytest integration e2e tests (ingestion→RAG)
│  └─ contract/               # contract tests for OpenAPI
└─ ci/
   ├─ pipeline.yaml           # example GitHub Actions / GitLab CI pipeline
   └─ deploy.sh

This layout aligns directly with the architecture and component responsibilities described in the spec and makes every piece testable independently @1 @11.

2) Per-service templates & responsibilities (concise, actionable)

- rag-service (FastAPI)
  - Responsibility: assemble context from Qdrant + Elasticsearch results, perform rank-fusion, call LLM Gateway to produce final answer, return answer + sources for grounded citations. See API contract /rag/query for request/response fields @6.
  - Key modules: retrieval clients (qdrant_client.py), bm25 client (bm25_client.py), rank-fusion utility, context_assembler, and API layer exposing /rag/query. Design to include request validation and tenant scoping on every call @6 @2.

- llm-gateway (Node.js/TypeScript)
  - Responsibility: accept LlmRequest from services (tenant_id, model, prompt, optional functions), route to cloud/local models, maintain circuit-breaker/retry policies, enforce prompt caching in Redis, and return LlmResponse (text, optional functionCall, tokens). Implement tenant-config-driven routing (tenant.config_json.high_accuracy_model etc.) and cost controls @3 @21.
  - Key modules: modelRouter (rules), promptCache (Redis TTL 24h with SHA256 key), metrics exporter, and fallback logic (degrade to local LLM on > threshold failures) @3 @21.

- tool-registry (FastAPI)
  - Responsibility: expose /tools/{tool_name}/invoke that validates incoming args against the JSON-Schema of the tool and executes the tool implementation (ticket creation, CRM call, email). Ensure every invocation logs to the audit table and supports synchronous and async (Webhook/callback) patterns @7 @23.
  - Contract: tools must register OpenAPI/JSON-Schema definitions and version them; orchestrator uses these definitions to construct and validate function-call payloads @7 @23.

- ingestion-worker (Python)
  - Responsibility: read Redis Streams (tenant-scoped), compute embeddings (sentence-transformers all-mpnet-base-v2 local fallback to OpenAI embeds), upsert into Qdrant collections per tenant, and emit metrics. Implement chunking rules (e.g., ~500 tokens), metadata enrichment, checksum change-detection, and reindex triggers @6 @2.

- botpress-extensions
  - Responsibility: custom actions to call RAG service, push handover events to Socket.IO namespace /handover, and attach provenance metadata to messages in the UI; provide flow nodes: detect_intent, handle_faq, start_refund_flow, handover @3 @6 @7.

- admin-ui (Next.js)
  - Responsibility: tenant registry management, prompt playground (GET /playground/metrics and POST /playground/evaluate), embedded n8n editor component for building orchestrator workflows, and dashboards that surface deflection rate, SLA breaches, and knowledge-gaps @5 @23 @29.

3) Dockerfile examples (copy/paste-ready)
Below are minimal but production-oriented Dockerfiles for core services. Each assumes a standard build pipeline and uses environment variables for secrets (injected via Kubernetes External Secrets/Vault).

- rag-service/Dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY services/rag-service/pyproject.toml services/rag-service/requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt
COPY services/rag-service/app ./app
ENV PYTHONUNBUFFERED=1
CMD ["uvicorn","app.main:app","--host","0.0.0.0","--port","8000","--log-level","info"]

(This service must export OpenTelemetry traces and Prometheus metrics for rag_query_duration_seconds as a histogram per the observability design) @6 @5.

- llm-gateway/Dockerfile
FROM node:20-alpine
WORKDIR /usr/src/app
COPY services/llm-gateway/package*.json ./
RUN npm ci --production
COPY services/llm-gateway/src ./src
ENV NODE_ENV=production
EXPOSE 3000
CMD ["node","dist/index.js"]

- tool-registry/Dockerfile (FastAPI)
FROM python:3.11-slim
WORKDIR /app
COPY services/tool-registry/requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt
COPY services/tool-registry/app ./app
CMD ["uvicorn","app.main:app","--host","0.0.0.0","--port","8080"]

- ingestion-worker/Dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY services/ingestion-worker/requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt
COPY services/ingestion-worker ./app
CMD ["python","/app/worker.py"]

These Dockerfiles follow the containerization and Helm packaging guidance in the spec and are designed to be extended with healthchecks, non-root users, and smaller base images for production @5 @12.

4) Helm chart skeletons and values.yaml snippets
Place these under infra/helm-charts/<service>.

Example values.yaml for rag-service (infra/helm-charts/rag-service/values.yaml):
replicaCount: 2
image:
  repository: myorg/rag-service
  tag: v0.1.0
service:
  type: ClusterIP
  port: 8000
resources:
  requests:
    cpu: 200m
    memory: 256Mi
  limits:
    cpu: 500m
    memory: 512Mi
env:
  - name: QDRANT_URL
    value: "qdrant:6333"
  - name: ELASTIC_URL
    value: "elasticsearch:9200"
  - name: REDIS_URL
    value: "redis:6379"
  - name: TENANT_REGISTRY_DB
    valueFrom:
      secretKeyRef:
        name: tenant-db-creds
        key: DATABASE_URL

Include readiness and liveness probes in templates/deployment.yaml and mount Kubernetes External Secrets for Vault-injected secrets; values.yaml should include per-tenant overlay options for dedicated instance charts (e.g., per-tenant resource overrides and collection prefixes). The use of replicaCount:2 and resource limits matches the low-level DevOps snippets in the design @5 @12.

Multi-tenant overlay strategy (brief)
- Shared-schema: deploy single rag-service Helm release that accepts tenant_id in requests; vector store will use collections per tenant and the rag-service must enforce tenant filters on retrievals @2 @6.
- Per-tenant dedicated: use Helmfile or ArgoCD App-of-Apps to instantiate rag-service per tenant with values.yaml overriding image tag, resource quotas, and database/collection scope for strict isolation @5 @21.

5) OpenAPI specs (YAML) — RAG and Tool Registry

- infra/openapi/rag-openapi.yaml (essential contract, copy-paste)
openapi: "3.0.3"
info:
  title: RAG Service API
  version: "1.0.0"
paths:
  /rag/query:
    post:
      summary: Retrieve and generate answer
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/RagRequest'
      responses:
        '200':
          description: Answer with citations
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RagResponse'
components:
  schemas:
    RagRequest:
      type: object
      required:
        - tenant_id
        - question
        - top_k
      properties:
        tenant_id:
          type: string
        question:
          type: string
        top_k:
          type: integer
    RagResponse:
      type: object
      properties:
        answer:
          type: string
        sources:
          type: array
          items:
            type: object
            properties:
              doc_id:
                type: string
              section:
                type: string
              score:
                type: number

This contract is taken directly from the low-level RAG API contract in your tech spec and must be propagated as the canonical contract for the rag-service implementation and contract tests @6.

- infra/openapi/tool-registry-openapi.yaml (essential)
openapi: "3.0.3"
info:
  title: Tool Registry API
  version: "1.0.0"
paths:
  /tools/{tool_name}/invoke:
    post:
      summary: Invoke a registered tool
      parameters:
        - name: tool_name
          in: path
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ToolInvokeRequest'
      responses:
        '200':
          description: Tool output
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ToolInvokeResponse'
components:
  schemas:
    ToolInvokeRequest:
      type: object
      properties:
        tenant_id:
          type: string
        tool_args:
          type: object
    ToolInvokeResponse:
      type: object
      properties:
        status:
          type: string
        result:
          type: object

Tool definitions must be versioned in a registry and expose JSON-Schema for their arguments, which the orchestrator uses for function-call validation; implement this as a small metadata table in Postgres and a file-store backing per tool @7 @23.

6) Contract tests (pytest + schemathesis / pydantic)
- Use schemathesis (OpenAPI fuzz + contract test) or pydantic-based contract tests to verify the live implementations match the OpenAPI specs in infra/openapi. Example pytest test (tests/contract/test_rag_contract.py):

import requests, json, pytest
from schemathesis import from_path

schema = from_path("infra/openapi/rag-openapi.yaml")

@schema.parametrize()
def test_api(case):
    # run against dev endpoint
    case.call_and_validate(base_url="http://localhost:8000")

- For tool-registry, use a parametrized test that posts representative tool payloads and asserts the response shape, status codes, and audit log side-effects (audit row created) @6 @7.

7) Terraform + Helm examples

A. Shared-schema cluster (infra/terraform/shared-deploy.tf)
- Provision k8s cluster (cloud provider module), deploy common infra (postgres, redis, qdrant), install ArgoCD, deploy helm releases for rag-service, llm-gateway, tool-registry and admin-ui. Store secrets in Vault and use Kubernetes External Secrets to inject credentials. Provide resource quotas and PodDisruptionBudget for each chart. This follows the GitOps and Helm recommendations in the spec and uses ArgoCD automated syncs @5 @21.

B. Per-tenant dedicated overlay (infra/terraform/per-tenant-deploy.tf)
- Module pattern: module "tenant_${var.tenant}" { source = "./modules/tenant" vars = { tenant_id = var.tenant_id image_tag = var.image_tag resources = { cpu = "..."} } }
- The tenant module will instantiate Helm releases with values overridden for tenant-specific DB schemas (or dedicated Postgres instance), Qdrant collection prefixes, and distinct Keycloak realms for strict isolation. Use Terraform to create per-tenant Vault key paths secret/data/tenant/{tenant_id}/keys and configure BYOK if requested @21 @29.

GitOps (ArgoCD): store the infra/argocd-apps manifests pointing at the git repo path for each tenant/overlay and configure automated sync every 5m per spec guidance @5.

8) End-to-end test harness (pytest + Playwright) — concrete tests

A. Ingestion → Embedding → RAG provenance (pytest)
- tests/e2e/pytest/test_ingest_rag.py (pseudocode)
1. Seed a test document (PDF/markdown) via ingestion API or push to Redis stream with tenant_id "test-tenant". @2 @6
2. Wait for ingestion-worker to process stream and upsert to Qdrant (poll Qdrant admin API for chunk_id presence).
3. POST /rag/query with tenant_id="test-tenant" question="text that matches seeded doc" top_k=5.
4. Assert status 200, response contains answer string, and sources array includes doc_id matching seeded doc and includes section and score fields.
5. Assert audit_log has an entry for the RAG query and the answer includes correct provenance (doc version id) @6 @24.

B. WebSocket handover flow (Playwright + pytest)
- tests/e2e/playwright/test_handover.spec.ts (pseudocode)
1. Start a browser Playwright session, open a page that mounts the Botpress web widget pointing to dev environment.
2. Simulate a user message "I want refund" that triggers Botpress flow with low-confidence fallback.
3. Assert Botpress emits bot_to_agent event (received by Socket.IO server) and that tool-registry create_ticket() was called (mock or spy).
4. Simulate an agent sending agent_to_user message via Socket.IO and assert the user widget receives the agent message and conversation state shows "You are now talking to Agent X".
5. Assert the ticket row exists in Postgres tickets table with tenant_id matching, and an audit log entry was created for the handover (persisted) @7 @35.

CI integration
- ci/pipeline.yaml includes steps to:
  - Build Docker images for all services.
  - Run unit tests for each service.
  - Start a local test k8s environment (kind or ephemeral cluster).
  - Deploy via Helm charts.
  - Run contract tests (schemathesis) against rag and tool-registry.
  - Run pytest ingestion/RAG e2e and Playwright handover tests.
  - On success, push images to registry and create ArgoCD PR for environment promotion. This matches the CI/CD and GitOps guidance in the design @5 @21.

9) Additional low-level code snippets (explicit) — paste-ready

- Airflow DAG (services/rag-service/examples/airflow_dags/ingest_cms_docs.py) — use the provided snippet as a template:
from airflow import DAG
from airflow.operators.python import PythonOperator
with DAG('ingest_cms_docs', schedule_interval='@hourly') as dag:
    fetch_confluence = PythonOperator(task_id='fetch_confluence', python_callable=fetch_confluence_docs)
    parse_docs       = PythonOperator(task_id='parse_docs', python_callable=parse_and_chunk)
    embed_chunks     = PythonOperator(task_id='embed_chunks', python_callable=embed_and_store)
    fetch_confluence >> parse_docs >> embed_chunks

This DAG skeleton is taken from the ingestion examples in the low-level spec and should be expanded with tenant context, error handling, and monitoring alerts @2.

- FastAPI tool invoke snippet (services/tool-registry/app/main.py)
from fastapi import FastAPI
app = FastAPI()
@app.post("/tools/{tool_name}/invoke")
def invoke_tool(tool_name: str, body: dict):
    tool = tool_definitions.get(tool_name)
    return tool.execute(body)

This is the exact skeleton recommended in the tech spec for a minimal tool registry @7.

- LLM Gateway TypeScript interface (services/llm-gateway/src/types.ts)
export interface LlmRequest {
  tenant_id: string;
  model: string;
  prompt: string;
  functions?: any[];
}
export interface LlmResponse {
  text: string;
  functionCall?: { name: string; arguments: any; };
  tokens: { input: number; output: number; };
}

Use the SHA256 cache key formula for prompt caching: SHA256(tenant_id + prompt_template + context_hash) TTL = 24h as documented in the low-level design @3.

10) Tests to include in repo (automated)
- Unit tests: pydantic model validations, qdrant client mocks, llm-gateway routing logic tests (simulate failures and assert degrade to local), and tool-registry argument validation tests. Ensure each unit test runs in CI with coverage gating. This maps to the unit/contract test directives in the technical design @21 @6.
- Contract tests (schemathesis) for RAG and Tool Registry OpenAPI specs.
- Integration tests: ingestion pipeline (Airflow + worker) verifying upsert to Qdrant and retrieval by rag-service.
- E2E tests: Playwright scenarios for handover and agent take-over, and pytest-based ingestion→RAG provenance tests verifying sources array content and audit log persistence @6 @7.

11) Terraform and secrets handling (important details)
- Vault integration: store per-tenant keys at secret/data/tenant/{tenant_id}/keys and reference them in values.yaml by key id rather than raw secrets in Repo; Kubernetes External Secrets (or external-secrets operator) will mount those into pods at runtime. This matches the BYOK & Vault recommendation in your requirements @29 @21.
- RLS policy: apply PostgreSQL Row-Level Security on metadata tables (tickets, audit_logs) by creating policies that require tenant_id = current_setting('app.tenant_id') or via application-level tenant_id injection enforced by JWT claims validated by Keycloak @2 @32.

12) Bootstrapping steps — first 10 git commits
Make those commits in order and push to repo to accelerate on-boarding:
1. repo scaffolding and README with architecture diagram @1.
2. rag-service FastAPI skeleton + Dockerfile + OpenAPI file @6.
3. tool-registry FastAPI skeleton + Dockerfile + OpenAPI file @7.
4. llm-gateway Node skeleton + Dockerfile + TypeScript interfaces @3.
5. ingestion-worker skeleton + Dockerfile + example Airflow DAG @2.
6. helm-charts base for rag-service + values.yaml (replicaCount, resources) @5.
7. terraform skeleton module for shared infra (postgres, redis) @21.
8. admin-ui Next.js skeleton + n8n embed placeholder @5.
9. basic pytest + schemathesis contract tests wired to OpenAPI specs @6.
10. Playwright + pytest sample handover test + CI pipeline YAML @7.

13) Security, governance and operational checks (must be enforced)
- Enforce tenant_id travel: every ingress request must include validated tenant_id from subdomain/JWT header and be checked in all services. This is mandatory and is the backbone of multi-tenancy implementation patterns described in the spec @32 @11.
- PII redaction: run Presidio or equivalent before content is persisted into vector store or DB and include a flag in chunk metadata indicating redaction status @5 @29.
- Audit trail immutability: write audit logs to append-only table and snapshot/backup regularly; consider signed audit records for tamper evidence as described in governance recommendations @5 @23.

14) Recommended README / developer onboarding content
- How to run services locally with docker-compose for dev (compose file that brings up Postgres, Redis, Qdrant, Elastic, rag-service, llm-gateway stub, tool-registry); include sample tenant seeded with SQL insert of tenants table SHOWING schema used (tenant_id UUID etc.) from the low-level spec @2.
- How to run contract tests (pip install -r requirements-dev.txt then pytest tests/contract).
- How to run e2e tests (start kind cluster or use a local dev cluster script in ci/deploy.sh then run pytest -k ingestion and npx playwright test for handover).
- How to register a new tool in the tool-registry (upload JSON-Schema definition and provide an execute() hook).

15) Deliverables I will create for you in the repo (what I will commit next)
- Complete monorepo skeleton with the files and placeholders above, including fully populated infra/openapi/rag-openapi.yaml and tool-registry-openapi.yaml, and initial unit/contract/e2e tests wired into a sample GH Actions pipeline. This follows your request exactly and the artifacts will be testable locally using the described steps @6 @7 @5.
- Terraform examples for shared-schema and per-tenant deployments including vault integration and ArgoCD app manifests for GitOps sync @21 @5.
- Playwright scenarios + pytest harness for the e2e flows described (ingestion→RAG provenance check and WebSocket handover) with mockable LLM responses and local Qdrant test instance @6 @7 @2.

References (selected, traceable to your documents)
- RAG API contract and retrieval logic: see RAG Service API and retrieval flow definitions @6.
- LLM Gateway interface, prompt caching key design, and routing/circuit-breaker rules: see LLM Gateway & prompt orchestration sections @3 @21.
- Tenant registry schema, tenant_id propagation, and multi-tenant isolation patterns: see Tenant Registry Schema and Multi-Tenant Configuration @2 @32.
- Redis Streams and embedding worker patterns; embedding model recommendation (all-mpnet-base-v2): see Embedding & Storage and ingestion worker descriptions @6.
- Tool Registry contract and orchestrator examples (n8n + AutoGen + LangChain): see Tool Registry FastAPI and n8n workflow snippets @7 @29.
- DevOps/Helm/GitOps examples and values.yaml snippets: see DevOps & Deployment Helm snippets and GitOps recommendation @5 @12.
- WebSocket handover namespace and events (Socket.IO): see WebSocket Handover specification @7.

Caveats & small open decisions you should confirm (I preserved these from the spec)
- Exact LLM vendor mapping (which cloud provider / model families for the high-accuracy fallback) — specify tenancy preferences in tenant.config_json so the gateway can route properly @3 @21.
- Qdrant collection naming and retention policy per-tenant — choose strict per-tenant collection naming (tenant_{tenant_id}_chunks) to simplify isolation or use metadata tenant_id with RLS-style enforcement, depending on cost vs isolation tradeoffs @2 @6.
- Governance gating thresholds and risk levels for Control Tower approvals — we can add a policy DSL in the repo if you want to make these runtime-configurable @29.

Next action from me (automated deliverable)
I will produce the full repository scaffold as described and push it to a repo skeleton you name (or I can provide as a downloadable tarball). The scaffold will include:
- All directories and files listed above with working skeleton code for rag-service, tool-registry, llm-gateway, ingestion-worker, botpress-extensions, and admin-ui; Dockerfiles; Helm charts (rag-service, llm-gateway, tool-registry); OpenAPI specs; Terraform skeletons; and test harness (pytest + Playwright) with at least one passing smoke e2e test using mocked model responses. This will be fully aligned to the low-level contracts and patterns in your documents @6 @7 @3 @5.

Please confirm:
1) Repo name and whether you want me to create a GitHub repo under a given org (I will supply the folder contents and instruct how to import), or produce a zip/tarball for you to import locally.  
2) Any preferences for CI provider (GitHub Actions / GitLab CI) and cloud provider for Terraform examples (AWS / GCP / Azure).  

Once confirmed I will generate the full repo scaffold and return either the repo push or a downloadable archive with commit history and instructions for local development.

